{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = ['', '/Users/jiazhuoqin/anaconda/lib/python27.zip', '/Users/jiazhuoqin/anaconda/lib/python2.7', '/Users/jiazhuoqin/anaconda/lib/python2.7/plat-darwin', '/Users/jiazhuoqin/anaconda/lib/python2.7/plat-mac', '/Users/jiazhuoqin/anaconda/lib/python2.7/plat-mac/lib-scriptpackages', '/Users/jiazhuoqin/anaconda/lib/python2.7/lib-tk', '/Users/jiazhuoqin/anaconda/lib/python2.7/lib-old', '/Users/jiazhuoqin/anaconda/lib/python2.7/lib-dynload', '/Users/jiazhuoqin/anaconda/lib/python2.7/site-packages', '/Users/jiazhuoqin/anaconda/lib/python2.7/site-packages/Sphinx-1.6.3-py2.7.egg', '/Users/jiazhuoqin/anaconda/lib/python2.7/site-packages/aeosa']\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from sklearn import linear_model\n",
    "#reload(sys) \n",
    "#sys.setdefaultencoding('utf8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiazhuoqin/anaconda/envs/gl-env/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (0,1,4,6,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('submissions.csv', encoding='utf-8', names = ['image_id','unixtime','rawtime','title','total_votes','reddit_id','number_of_upvotes',\\\n",
    "'subreddit','number_of_downvotes','localtime','score','number_of_comments','username',\\\n",
    "'undefined1','undefined2', 'undefined3']\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.iloc[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = df['title'].tolist()\n",
    "subreddit = df['subreddit'].tolist()\n",
    "score = df['score'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get x and subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "    \n",
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in titles:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "  \n",
    "    # stem tokens\n",
    "    try:\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    except:\n",
    "        print i\n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)  #data 1 texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4577\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "count = defaultdict(int)\n",
    "\n",
    "for document in texts:\n",
    "    for stem in document:\n",
    "        count[stem] += 1\n",
    "        \n",
    "for letter in list('abcdedfgijklmnopqrstuvwxyz'):\n",
    "    if letter in count:\n",
    "        count.pop(letter)\n",
    "        \n",
    "words_cut = [(item[1] , item[0]) for item in count.items() if item[1] > 10]\n",
    "words_sort = sorted(words_cut,reverse = True)\n",
    "len_words = len(words_sort) # data 3 len of frequent words\n",
    "print len(words_sort)\n",
    "\n",
    "words_cut_sorted = [item[1] for item in words_sort]  # data 2 frequent words(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use frequent stem to predict score (influence of stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_stem = []\n",
    "for document in texts:\n",
    "    temp = [1] + [0] * len_words\n",
    "    for item in document:\n",
    "        if item in words_cut_sorted:\n",
    "            temp[words_cut_sorted.index(item) + 1] += 1\n",
    "    X_stem.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132307\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#score has been got\n",
    "Y_score = []\n",
    "for item in score:\n",
    "    Y_score.append(int(item))\n",
    "print len(score)\n",
    "print score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X_stem, Y_score) # when using all set of data, MEMORY ERROR!!!\n",
    "theta = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = theta.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#store word-theta pairs\n",
    "f = open('theta.txt','w')\n",
    "max1 = max(theta)\n",
    "min1 = min(theta)\n",
    "max_index = theta.index(max1)\n",
    "min_index = theta.index(min1)\n",
    "\n",
    "f.write('the max theta is ' + words_cut_sorted[max_index] + ': ' + str(theta[max_index]) + '\\n')\n",
    "f.write('the min theta is ' + words_cut_sorted[min_index] + ': ' + str(theta[min_index]) + '\\n')\n",
    "for x in range(len(theta)):\n",
    "    try:\n",
    "        f.write(words_cut_sorted[x] + ': ' + str(theta[x]) + '\\n')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check result's R^2 and mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217584.005219\n",
      "0.0600356785449\n"
     ]
    }
   ],
   "source": [
    "mse = 0\n",
    "\n",
    "for i in range(132307):\n",
    "    temp = 0\n",
    "    for j in range(len_words + 1):\n",
    "        temp += X_stem[i][j] * theta[j]\n",
    "    mse += (Y_score[i] - temp) ** 2\n",
    "mse = mse *1.0 / 132307\n",
    "print mse\n",
    "print clf.score(X_stem, Y_score, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "899\n",
      "[ 243.79549109    9.33716888  -36.6641914   -27.60457848  -19.00734995\n",
      "   -4.72793876  -19.45460056   -6.32457961  -26.9228977     7.90470621\n",
      "    6.85685518  -15.94852879   41.29603368  -14.97874384   -4.06019382\n",
      "  -17.92337457  -17.83340635   -0.67876939   26.55750396   47.89755628\n",
      "  -31.45924949  -19.7875087    11.72490203   -6.11687528   34.80934735\n",
      "  -22.04414761   -3.60983512    7.06458181   13.46278737  -17.61563304\n",
      "  -11.22274791    1.12022952    4.01644004   20.06954561  -93.04873768\n",
      "  -13.02918789  -21.32921893    9.13645911   23.09404815  -15.4077732\n",
      "   58.89583205   17.90348274  -35.53761995   -1.91065149   24.52194482\n",
      "   -9.27750016  -14.55793172    3.34561524    7.33391673  -29.6799541\n",
      "   17.41247944   -0.97292458   -1.45907993  -48.89434959   22.44322598\n",
      "  -33.07361742  -15.55227514  -26.96164552   29.35984779  -50.90504698\n",
      "    9.24708458    7.89510548   24.8929253   -73.22655481   16.38576638\n",
      "   15.83901878  -16.24412451  -89.77765077  -50.02427683  148.60101173\n",
      "   -1.61807084   21.19358612  -29.26726918   32.68632164  -51.60010985\n",
      "  -88.34645502    6.22556643  -18.02530288  -29.8781078   -11.3584218\n",
      "  -34.54988601  -48.88084714   12.80363364  -40.09023285  -58.65755176\n",
      "    2.00304524  -60.62329783  -13.22291768  -32.16690673   38.12586812\n",
      "   -4.55317332   20.31247643    1.4575681    42.37655042  -12.8801113\n",
      "   11.33785983  -62.68064846   -3.64247734    8.12559769    9.98562684]\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print len(theta)\n",
    "print len(words_cut_sorted)\n",
    "print theta[:100]\n",
    "print words_cut_sorted.index(u'dog')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
